{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOG61h5VGPHPkKT0fTW6+0/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chapter-4 Assignments"],"metadata":{"id":"onqM5GkyecGh"}},{"cell_type":"markdown","source":["**Installed the required Python prerequisite packages and libraries.**"],"metadata":{"id":"1U1gzz209tTt"}},{"cell_type":"code","source":["!pip install hmmlearn tensorflow keras"],"metadata":{"id":"1oMrvNJl9urm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 1: N-grams"],"metadata":{"id":"Rv6UNlkUeg58"}},{"cell_type":"code","source":["from nltk import ngrams\n","import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","# Sample text\n","text = \"Natural Language Processing with Python\"\n","\n","# Tokenize the text into words\n","tokens = nltk.word_tokenize(text)\n","\n","# Generate trigrams\n","trigrams = ngrams(tokens, 3)\n","\n","print(\"Trigrams:\")\n","for grams in trigrams:\n","    print(grams)"],"metadata":{"id":"aPtDaOeueivm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"EOIrBrABhA7N"}},{"cell_type":"markdown","source":["Exercise 2: Bigram Language Model"],"metadata":{"id":"euyam56Jellx"}},{"cell_type":"code","source":["corpus = [\n","    \"Natural Language Processing is fascinating.\",\n","    \"Language models are important in NLP.\",\n","    \"Machine learning and NLP are closely related.\"\n","]"],"metadata":{"id":"zNHvS8eIemJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","import numpy as np\n","from nltk import ngrams\n","import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","# Sample text corpus\n","corpus = [\n","    \"Natural Language Processing is fascinating.\",\n","    \"Language models are important in NLP.\",\n","    \"Machine learning and NLP are closely related.\"\n","]\n","\n","# Tokenize the text into words\n","tokenized_corpus = [nltk.word_tokenize(sentence) for sentence in corpus]\n","\n","# Function to calculate bigram probabilities\n","def train_bigram_model(tokenized_corpus):\n","    model = defaultdict(lambda: defaultdict(lambda: 0))\n","\n","    # Count bigrams\n","    for sentence in tokenized_corpus:\n","        for w1, w2 in ngrams(sentence, 2):\n","            model[w1][w2] += 1\n","\n","    # Calculate probabilities\n","    for w1 in model:\n","        total_count = float(sum(model[w1].values()))\n","        for w2 in model[w1]:\n","            model[w1][w2] /= total_count\n","\n","    return model\n","\n","# Train the bigram model\n","bigram_model = train_bigram_model(tokenized_corpus)\n","\n","# Function to get the probability of a bigram\n","def get_bigram_probability(bigram_model, w1, w2):\n","    return bigram_model[w1][w2]\n","\n","print(\"Bigram Probability (Processing | Language):\")\n","print(get_bigram_probability(bigram_model, 'Language', 'Processing'))"],"metadata":{"id":"OKBuCdvneniy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"52hcANPFhCGq"}},{"cell_type":"markdown","source":["Exercise 3: HMM for Part-of-Speech Tagging"],"metadata":{"id":"WNZINlPzermh"}},{"cell_type":"code","source":["sentences = [\n","    [\"I\", \"run\", \"to\", \"the\", \"store\"],\n","    [\"She\", \"jumps\", \"over\", \"the\", \"fence\"]\n","]\n","\n","tags = [\n","    [\"PRON\", \"VERB\", \"ADP\", \"DET\", \"NOUN\"],\n","    [\"PRON\", \"VERB\", \"ADP\", \"DET\", \"NOUN\"]\n","]"],"metadata":{"id":"Q9NOgn86esOT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"nWo2b4LohC5s"}},{"cell_type":"code","source":["import numpy as np\n","from hmmlearn import hmm\n","\n","# Define the states and observations\n","states = [\"PRON\", \"VERB\", \"ADP\", \"DET\", \"NOUN\"]\n","n_states = len(states)\n","\n","observations = [\"I\", \"run\", \"to\", \"the\", \"store\", \"She\", \"jumps\", \"over\", \"fence\"]\n","n_observations = len(observations)\n","\n","# Encode the states and observations\n","state_to_idx = {state: idx for idx, state in enumerate(states)}\n","observation_to_idx = {obs: idx for idx, obs in enumerate(observations)}\n","\n","# Create the sequences for training\n","X = [[observation_to_idx[word] for word in sentence] for sentence in sentences]\n","y = [[state_to_idx[tag] for tag in tag_sequence] for tag_sequence in tags]\n","\n","# Convert to numpy arrays\n","X = np.concatenate([np.array(x).reshape(-1, 1) for x in X])\n","lengths = [len(x) for x in sentences]\n","y = np.concatenate(y)\n","\n","# Create the HMM model\n","model = hmm.MultinomialHMM(n_components=n_states, n_iter=100)\n","model.fit(X, lengths)\n","\n","# Predict the hidden states (decoding problem)\n","logprob, hidden_states = model.decode(X, algorithm=\"viterbi\")\n","\n","# Map the states back to their original labels\n","hidden_states = [states[state] for state in hidden_states]\n","\n","print(\"Observations:\", sentences[0] + sentences[1])\n","print(\"Predicted states:\", hidden_states)"],"metadata":{"id":"kzOHW6KfevYv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"DKklGJoxhD0I"}},{"cell_type":"markdown","source":["Exercise 4: Simple RNN for Text Generation"],"metadata":{"id":"RRQDOdIAexId"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, SimpleRNN\n","from tensorflow.keras.utils import to_categorical\n","\n","# Sample text corpus\n","text = \"hello world\"\n","\n","# Create a character-level vocabulary\n","chars = sorted(set(text))\n","char_to_idx = {char: idx for idx, char in enumerate(chars)}\n","idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n","\n","# Create input-output pairs for training\n","sequence_length = 3\n","X = []\n","y = []\n","for i in range(len(text) - sequence_length):\n","    X.append([char_to_idx[char] for char in text[i:i + sequence_length]])\n","    y.append(char_to_idx[text[i + sequence_length]])\n","\n","X = np.array(X)\n","y = to_categorical(y, num_classes=len(chars))\n","\n","# Reshape input to be compatible with RNN input\n","X = X.reshape((X.shape[0], X.shape[1], 1))\n","\n","# Define the RNN model\n","model = Sequential()\n","model.add(SimpleRNN(50, input_shape=(sequence_length, 1)))\n","model.add(Dense(len(chars), activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","\n","# Train the model\n","model.fit(X, y, epochs=200, verbose=1)\n","\n","# Function to generate text using the trained model\n","def generate_text(model, start_string, num_generate):\n","    input_eval = [char_to_idx[s] for s in start_string]\n","    input_eval = np.array(input_eval).reshape((1, len(input_eval), 1))\n","\n","    text_generated = []\n","\n","    for i in range(num_generate):\n","        predictions = model.predict(input_eval)\n","        predicted_id = np.argmax(predictions[-1])\n","\n","        # Reshape predicted_id to have the same number of dimensions as input_eval\n","        predicted_id = np.array(predicted_id).reshape((1, 1, 1))\n","\n","        input_eval = np.append(input_eval[:, 1:], predicted_id, axis=1)\n","        text_generated.append(idx_to_char[predicted_id[0][0][0]])\n","\n","    return start_string + ''.join(text_generated)\n","\n","# Generate new text\n","start_string = \"hel\"\n","generated_text = generate_text(model, start_string, 5)\n","print(\"Generated text:\")\n","print(generated_text)"],"metadata":{"id":"ALzs_etUexv-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"sMi3rv2ahEzm"}},{"cell_type":"markdown","source":["Exercise 5: LSTM for Text Generation"],"metadata":{"id":"cySCijdwe6Av"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","from tensorflow.keras.utils import to_categorical\n","\n","# Sample text corpus\n","text = \"hello world\"\n","\n","# Create a character-level vocabulary\n","chars = sorted(set(text))\n","char_to_idx = {char: idx for idx, char in enumerate(chars)}\n","idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n","\n","# Create input-output pairs for training\n","sequence_length = 3\n","X = []\n","y = []\n","for i in range(len(text) - sequence_length):\n","    X.append([char_to_idx[char] for char in text[i:i + sequence_length]])\n","    y.append(char_to_idx[text[i + sequence_length]])\n","\n","X = np.array(X)\n","y = to_categorical(y, num_classes=len(chars))\n","\n","# Reshape input to be compatible with LSTM input\n","X = X.reshape((X.shape[0], X.shape[1], 1))\n","\n","# Define the LSTM model\n","model = Sequential()\n","model.add(LSTM(50, input_shape=(sequence_length, 1)))\n","model.add(Dense(len(chars), activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","\n","# Train the model\n","model.fit(X, y, epochs=200, verbose=1)\n","\n","# Function to generate text using the trained model\n","def generate_text(model, start_string, num_generate):\n","    input_eval = [char_to_idx[s] for s in start_string]\n","    input_eval = np.array(input_eval).reshape((1, len(input_eval), 1))\n","\n","    text_generated = []\n","\n","    for i in range(num_generate):\n","        predictions = model.predict(input_eval)\n","        predicted_id = np.argmax(predictions[-1])\n","\n","        # Reshape predicted_id to match the dimensions of input_eval\n","        predicted_id = np.array(predicted_id).reshape((1, 1, 1))\n","\n","        input_eval = np.append(input_eval[:, 1:], predicted_id, axis=1)\n","        text_generated.append(idx_to_char[predicted_id[0][0][0]])\n","\n","    return start_string + ''.join(text_generated)\n","\n","# Generate new text\n","start_string = \"hel\"\n","generated_text = generate_text(model, start_string, 5)\n","print(\"Generated text:\")\n","print(generated_text)"],"metadata":{"id":"2_EAxs4ye8lC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"j5UjFnbDhFsy"}}]}