{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 8.1 Extractive Summarization"],"metadata":{"id":"kxunHxq4qVPD"}},{"cell_type":"markdown","source":["8.1.2 Implementing Extractive Summarization"],"metadata":{"id":"KWtbXAgMqaPL"}},{"cell_type":"code","source":["!pip install sumy nltk"],"metadata":{"id":"wEx78a0Cqb2P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.probability import FreqDist\n","from nltk.cluster.util import cosine_distance\n","import numpy as np\n","import networkx as nx\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab') # Download the missing resource\n","\n","# Sample text\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# Preprocess the text\n","sentences = sent_tokenize(text)\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_sentence(sentence):\n","    words = word_tokenize(sentence.lower())\n","    words = [word for word in words if word.isalnum() and word not in stop_words]\n","    return words\n","\n","# Sentence scoring based on term frequency\n","def score_sentences(sentences):\n","    sentence_scores = []\n","    word_frequencies = FreqDist([word for sentence in sentences for word in preprocess_sentence(sentence)])\n","\n","    for sentence in sentences:\n","        words = preprocess_sentence(sentence)\n","        sentence_score = sum(word_frequencies[word] for word in words)\n","        sentence_scores.append((sentence, sentence_score))\n","\n","    return sentence_scores\n","\n","# Select top-ranked sentences\n","def select_sentences(sentence_scores, num_sentences=2):\n","    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n","    selected_sentences = [sentence[0] for sentence in sentence_scores[:num_sentences]]\n","    return selected_sentences\n","\n","# Generate summary\n","sentence_scores = score_sentences(sentences)\n","summary_sentences = select_sentences(sentence_scores)\n","summary = ' '.join(summary_sentences)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"y1k2dQvFqh-x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8.1.3 Advanced Extractive Summarization Techniques"],"metadata":{"id":"AjR8YWnVrW0k"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","import numpy as np\n","import networkx as nx\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# NLTK downloads (depending on the environment, 'punkt_tab' may also be required)\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Sample text (replace with the reader's input)\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# 1) Sentences and light normalization\n","sentences = [s for s in sent_tokenize(text) if s.strip()]\n","stop_words = set(stopwords.words('english'))\n","\n","def normalize(s):\n","    tokens = [w for w in word_tokenize(s.lower()) if w.isalnum() and w not in stop_words]\n","    return \" \".join(tokens)\n","\n","normalized = [normalize(s) for s in sentences]\n","\n","# 2) TF-IDF vectorization per sentence\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(normalized)   # shape: (n_sentences, vocab_size)\n","\n","# 3) Cosine similarity matrix\n","sim_matrix = cosine_similarity(X, X)\n","np.fill_diagonal(sim_matrix, 0.0)          # avoid dominant self-loops\n","\n","# 4) TextRank with NetworkX (PageRank over the similarity graph)\n","graph = nx.from_numpy_array(sim_matrix)\n","scores = nx.pagerank(graph)\n","\n","# 5) Selection of top-ranked sentences\n","num_sentences = 2\n","ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n","summary_sentences = [s for _, s in ranked[:num_sentences]]\n","summary = \" \".join(summary_sentences)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"qd3vVh3PrhX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample documents\n","documents = [\n","    \"The cat sat on the mat\",\n","    \"The dog chased the ball\",\n","    \"The bird flew in the sky\"\n","]\n","\n","# Create a term-document matrix (one-hot encoded)\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer = CountVectorizer()\n","term_document_matrix = vectorizer.fit_transform(documents)\n","\n","# Perform Singular Value Decomposition (SVD)\n","from sklearn.decomposition import TruncatedSVD\n","svd = TruncatedSVD(n_components=2)  # Reduce dimensionality to 2 for visualization\n","lsa_matrix = svd.fit_transform(term_document_matrix)\n","\n","# Reduced term and document representations (topics)\n","terms = vectorizer.get_feature_names_out()\n","lsa_topics = svd.components_\n","\n","# Print the results (example)\n","print(\"Terms:\", terms)\n","print(\"Reduced Document Representations (Topics):\")\n","print(lsa_matrix)\n","print(\"Reduced Term Representations (Topics):\")\n","print(lsa_topics)"],"metadata":{"id":"TPB3mR_Ur2hZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8.2 Abstractive Summarization"],"metadata":{"id":"OyZmvslotL-f"}},{"cell_type":"markdown","source":["8.2.2 Implementing Abstractive Summarization"],"metadata":{"id":"b0oT45dOtOQO"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"x4pqOU6CtPr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BartForConditionalGeneration, BartTokenizer\n","\n","# Load the pre-trained BART model and tokenizer\n","model_name = \"facebook/bart-large-cnn\"\n","model = BartForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = BartTokenizer.from_pretrained(model_name)\n","\n","# Sample text\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# Tokenize and encode the text\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"NHs_YDzItRpu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8.2.3 Advanced Abstractive Summarization Techniques"],"metadata":{"id":"-xoMt50GtVB8"}},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# Load the pre-trained T5 model and tokenizer\n","model_name = \"t5-small\"\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","\n","# Sample text\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# Tokenize and encode the text\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"Fm1uefattVvm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chapter-8 Assignments"],"metadata":{"id":"rvsPrNlWtbiP"}},{"cell_type":"markdown","source":["Exercise 1: Extractive Summarization with NLTK"],"metadata":{"id":"S5QxZEWhthsx"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.probability import FreqDist\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Sample text\n","text = \"\"\"Machine learning is a subset of artificial intelligence. It involves algorithms and statistical models to perform tasks without explicit instructions. Machine learning is widely used in various applications such as image recognition, natural language processing, and autonomous driving. It relies on patterns and inference instead of predefined rules.\"\"\"\n","\n","# Preprocess the text\n","sentences = sent_tokenize(text)\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_sentence(sentence):\n","    words = word_tokenize(sentence.lower())\n","    words = [word for word in words if word.isalnum() and word not in stop_words]\n","    return words\n","\n","# Sentence scoring based on term frequency\n","def score_sentences(sentences):\n","    sentence_scores = []\n","    word_frequencies = FreqDist([word for sentence in sentences for word in preprocess_sentence(sentence)])\n","\n","    for sentence in sentences:\n","        words = preprocess_sentence(sentence)\n","        sentence_score = sum(word_frequencies[word] for word in words)\n","        sentence_scores.append((sentence, sentence_score))\n","\n","    return sentence_scores\n","\n","# Select top-ranked sentences\n","def select_sentences(sentence_scores, num_sentences=2):\n","    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n","    selected_sentences = [sentence[0] for sentence in sentence_scores[:num_sentences]]\n","    return selected_sentences\n","\n","# Generate summary\n","sentence_scores = score_sentences(sentences)\n","summary_sentences = select_sentences(sentence_scores)\n","summary = ' '.join(summary_sentences)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"XKpZ85GEtjbo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"fWjaBhMTuLmF"}},{"cell_type":"markdown","source":["Exercise 2: Extractive Summarization with TextRank"],"metadata":{"id":"LqTCSVbGtnE-"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.cluster.util import cosine_distance\n","import numpy as np\n","import networkx as nx\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Sample text\n","text = \"\"\"Machine learning is a subset of artificial intelligence. It involves algorithms and statistical models to perform tasks without explicit instructions. Machine learning is widely used in various applications such as image recognition, natural language processing, and autonomous driving. It relies on patterns and inference instead of predefined rules.\"\"\"\n","\n","# Preprocess the text\n","sentences = sent_tokenize(text)\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_sentence(sentence):\n","    words = word_tokenize(sentence.lower())\n","    words = [word for word in words if word.isalnum() and word not in stop_words]\n","    return words\n","\n","# Build sentence similarity matrix\n","def build_similarity_matrix(sentences):\n","    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n","\n","    for i, sentence1 in enumerate(sentences):\n","        for j, sentence2 in enumerate(sentences):\n","            if i != j:\n","                words1 = preprocess_sentence(sentence1)\n","                words2 = preprocess_sentence(sentence2)\n","                similarity_matrix[i][j] = 1 - cosine_distance(words1, words2)\n","\n","    return similarity_matrix\n","\n","# Apply TextRank algorithm\n","def textrank(sentences, num_sentences=2):\n","    similarity_matrix = build_similarity_matrix(sentences)\n","    similarity_graph = nx.from_numpy_array(similarity_matrix)\n","    scores = nx.pagerank(similarity_graph)\n","\n","    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n","    selected_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n","\n","    return selected_sentences\n","\n","# Generate summary\n","summary_sentences = textrank(sentences)\n","summary = ' '.join(summary_sentences)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"zdi2JiOvtniB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"7GykdoEKuMuX"}},{"cell_type":"markdown","source":["Exercise 3: Abstractive Summarization with BART"],"metadata":{"id":"Ep7BcH7Itq8Z"}},{"cell_type":"code","source":["from transformers import BartForConditionalGeneration, BartTokenizer\n","\n","# Load the pre-trained BART model and tokenizer\n","model_name = \"facebook/bart-large-cnn\"\n","model = BartForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = BartTokenizer.from_pretrained(model_name)\n","\n","# Sample text\n","text = \"\"\"Machine learning is a subset of artificial intelligence. It involves algorithms and statistical models to perform tasks without explicit instructions. Machine learning is widely used in various applications such as image recognition, natural language processing, and autonomous driving. It relies on patterns and inference instead of predefined rules.\"\"\"\n","\n","# Tokenize and encode the text\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=100, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"RMdMC75ltrkh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"cRAGui7suNr-"}},{"cell_type":"markdown","source":["Exercise 4: Abstractive Summarization with T5"],"metadata":{"id":"iu7Qz78Qtt4h"}},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# Load the pre-trained T5 model and tokenizer\n","model_name = \"t5-small\"\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","\n","# Sample text\n","text = \"\"\"Machine learning is a subset of artificial intelligence. It involves algorithms and statistical models to perform tasks without explicit instructions. Machine learning is widely used in various applications such as image recognition, natural language processing, and autonomous driving. It relies on patterns and inference instead of predefined rules.\"\"\"\n","\n","# Tokenize and encode the text\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=100, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"1rBtsAO9tuYc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"ov9zYDxNuOcW"}}]}