{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 7.1 Latent Semantic Analysis (LSA)"],"metadata":{"id":"WI1mxRQ0oLgR"}},{"cell_type":"markdown","source":["7.1.3 Implementing LSA in Python."],"metadata":{"id":"-7PxuMmuoOJE"}},{"cell_type":"code","source":["!pip install scikit-learn"],"metadata":{"id":"VHkI4iJtoQER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","\n","# Sample text corpus\n","corpus = [\n","    \"The cat sat on the mat.\",\n","    \"The dog sat on the log.\",\n","    \"The cat chased the dog.\",\n","    \"The dog chased the cat.\"\n","]\n","\n","# Create a TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","\n","# Apply LSA using TruncatedSVD\n","lsa = TruncatedSVD(n_components=2, random_state=42)\n","X_reduced = lsa.fit_transform(X)\n","\n","# Print the terms and their corresponding components\n","terms = vectorizer.get_feature_names_out()\n","for i, comp in enumerate(lsa.components_):\n","    terms_comp = zip(terms, comp)\n","    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:5]\n","    print(f\"Topic {i}:\")\n","    for term, weight in sorted_terms:\n","        print(f\" - {term}: {weight:.4f}\")"],"metadata":{"id":"WqKyv6WdoUw2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7.2 Latent Dirichlet Allocation (LDA)"],"metadata":{"id":"n3RjzdA6oafs"}},{"cell_type":"markdown","source":["7.2.3 Implementing LDA in Python"],"metadata":{"id":"eWIg34p8ocKh"}},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import LdaModel\n","from pprint import pprint\n","\n","# Sample text corpus\n","corpus = [\n","    \"The cat sat on the mat.\",\n","    \"The dog sat on the log.\",\n","    \"The cat chased the dog.\",\n","    \"The dog chased the cat.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents\n","dictionary = corpora.Dictionary(texts)\n","\n","# Convert the dictionary to a bag-of-words representation of the corpus\n","corpus_bow = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train the LDA model\n","lda_model = LdaModel(corpus=corpus_bow, id2word=dictionary, num_topics=2, random_state=42, passes=10)\n","\n","# Print the topics\n","print(\"Topics:\")\n","pprint(lda_model.print_topics(num_words=5))\n","\n","# Assign topics to a new document\n","new_doc = \"The cat chased the dog.\"\n","new_doc_bow = dictionary.doc2bow(new_doc.lower().split())\n","print(\"\\\\nTopic Distribution for the new document:\")\n","pprint(lda_model.get_document_topics(new_doc_bow))"],"metadata":{"id":"0OLzN8eeod-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7.2.4 Interpreting LDA Results"],"metadata":{"id":"9ipoo0hzoh6P"}},{"cell_type":"code","source":["from gensim.models.coherencemodel import CoherenceModel\n","\n","# Compute Coherence Score\n","coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n","coherence_lda = coherence_model_lda.get_coherence()\n","print(f\"Coherence Score: {coherence_lda}\")"],"metadata":{"id":"CjvyJ6TBoiji"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7.3 Hierarchical Dirichlet Process (HDP)"],"metadata":{"id":"0fPfVG8kotpo"}},{"cell_type":"markdown","source":["7.3.3 Implementing HDP in Python"],"metadata":{"id":"bhscXPKhovlG"}},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"id":"Csrb8nzqoxUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import HdpModel\n","from pprint import pprint\n","\n","# Sample text corpus\n","corpus = [\n","    \"The cat sat on the mat.\",\n","    \"The dog sat on the log.\",\n","    \"The cat chased the dog.\",\n","    \"The dog chased the cat.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents\n","dictionary = corpora.Dictionary(texts)\n","\n","# Convert the dictionary to a bag-of-words representation of the corpus\n","corpus_bow = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train the HDP model\n","hdp_model = HdpModel(corpus=corpus_bow, id2word=dictionary)\n","\n","# Print the topics\n","print(\"Topics:\")\n","pprint(hdp_model.print_topics(num_topics=2, num_words=5))\n","\n","# Assign topics to a new document\n","new_doc = \"The cat chased the dog.\"\n","new_doc_bow = dictionary.doc2bow(new_doc.lower().split())\n","print(\"\\\\nTopic Distribution for the new document:\")\n","pprint(hdp_model[new_doc_bow])"],"metadata":{"id":"0KR3jr0pozKJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7.3.4 Interpreting HDP Results"],"metadata":{"id":"MdxAglP2o2AE"}},{"cell_type":"code","source":["from gensim.models.coherencemodel import CoherenceModel\n","\n","# Compute Coherence Score\n","coherence_model_hdp = CoherenceModel(model=hdp_model, texts=texts, dictionary=dictionary, coherence='c_v')\n","coherence_hdp = coherence_model_hdp.get_coherence()\n","print(f\"Coherence Score: {coherence_hdp}\")"],"metadata":{"id":"NhyvYkHPo3_V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chapter-7 Assignments"],"metadata":{"id":"_qi9Kevho8ax"}},{"cell_type":"markdown","source":["Exercise 1: Latent Semantic Analysis (LSA)"],"metadata":{"id":"HTfE14QXpA2A"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","\n","# Sample text corpus\n","corpus = [\n","    \"Data science is an interdisciplinary field.\",\n","    \"Machine learning is a subset of data science.\",\n","    \"Artificial intelligence is a broader concept than machine learning.\",\n","    \"Deep learning is a subset of machine learning.\"\n","]\n","\n","# Create a TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","\n","# Apply LSA using TruncatedSVD\n","lsa = TruncatedSVD(n_components=2, random_state=42)\n","X_reduced = lsa.fit_transform(X)\n","\n","# Print the terms and their corresponding components\n","terms = vectorizer.get_feature_names_out()\n","for i, comp in enumerate(lsa.components_):\n","    terms_comp = zip(terms, comp)\n","    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:5]\n","    print(f\"Topic {i}:\")\n","    for term, weight in sorted_terms:\n","        print(f\" - {term}: {weight:.4f}\")"],"metadata":{"id":"_WkOj2vOpCjR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"aQaMOP-UqGHw"}},{"cell_type":"markdown","source":["Exercise 2: Latent Dirichlet Allocation (LDA)"],"metadata":{"id":"T7jgVOnOpF6X"}},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"id":"AnB29sZmpcax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import LdaModel\n","from pprint import pprint\n","\n","# Sample text corpus\n","corpus = [\n","    \"Natural language processing enables computers to understand human language.\",\n","    \"Computer vision allows machines to interpret and make decisions based on visual data.\",\n","    \"Robotics combines engineering and computer science to create intelligent machines.\",\n","    \"Quantum computing leverages quantum mechanics to perform complex calculations.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents\n","dictionary = corpora.Dictionary(texts)\n","\n","# Convert the dictionary to a bag-of-words representation of the corpus\n","corpus_bow = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train the LDA model\n","lda_model = LdaModel(corpus=corpus_bow, id2word=dictionary, num_topics=2, random_state=42, passes=10)\n","\n","# Print the topics\n","print(\"Topics:\")\n","pprint(lda_model.print_topics(num_topics=2, num_words=5))"],"metadata":{"id":"alPvWXBRpHbs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"uyn8l5fcqHat"}},{"cell_type":"markdown","source":["Exercise 3: Hierarchical Dirichlet Process (HDP)"],"metadata":{"id":"2VSffPlUpJnW"}},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import HdpModel\n","from pprint import pprint\n","\n","# Sample text corpus\n","corpus = [\n","    \"Climate change impacts global weather patterns.\",\n","    \"Renewable energy sources reduce carbon emissions.\",\n","    \"Biodiversity is essential for ecosystem balance.\",\n","    \"Conservation efforts protect endangered species.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents\n","dictionary = corpora.Dictionary(texts)\n","\n","# Convert the dictionary to a bag-of-words representation of the corpus\n","corpus_bow = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train the HDP model\n","hdp_model = HdpModel(corpus=corpus_bow, id2word=dictionary)\n","\n","# Print the topics\n","print(\"Topics:\")\n","pprint(hdp_model.print_topics(num_topics=2, num_words=5))"],"metadata":{"id":"6JbG-30ipLZv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"kWcK_DjOqIt6"}},{"cell_type":"markdown","source":["Exercise 4: Evaluating Topic Coherence"],"metadata":{"id":"2WyU7N2qpOZ8"}},{"cell_type":"code","source":["from gensim.models.coherencemodel import CoherenceModel\n","from gensim import corpora\n","\n","# Sample text corpus used to train the LDA model in cell `alPvWXBRpHbs`\n","corpus = [\n","    \"Natural language processing enables computers to understand human language.\",\n","    \"Computer vision allows machines to interpret and make decisions based on visual data.\",\n","    \"Robotics combines engineering and computer science to create intelligent machines.\",\n","    \"Quantum computing leverages quantum mechanics to perform complex calculations.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents using the correct corpus\n","dictionary = corpora.Dictionary(texts)\n","\n","\n","# Compute Coherence Score\n","coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n","coherence_lda = coherence_model_lda.get_coherence()\n","print(f\"Coherence Score: {coherence_lda}\")"],"metadata":{"id":"u7jIIyDipQXM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"rQa0TkyCqJl4"}},{"cell_type":"markdown","source":["Exercise 5: Assigning Topics to New Documents"],"metadata":{"id":"76b3sC5VpTFl"}},{"cell_type":"code","source":["# New document\n","new_doc = \"Renewable energy is crucial for combating climate change.\"\n","new_doc_bow = dictionary.doc2bow(new_doc.lower().split())\n","\n","# Assign topics to the new document\n","print(\"Topic Distribution for the new document:\")\n","pprint(hdp_model[new_doc_bow])"],"metadata":{"id":"YFjZ_slUpUxD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"guzoBh-9qKjk"}}]}