{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO4TlovHao1lZviEiO+cyBT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chapter-3 Assignments"],"metadata":{"id":"oEChii1Jae1n"}},{"cell_type":"markdown","source":["**Installed the required Python prerequisite packages and libraries.**"],"metadata":{"id":"Q-MXBBHj9avy"}},{"cell_type":"code","source":["!pip install gensim nltk transformers"],"metadata":{"id":"4d-qbnDe9c1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exercise 1: Bag of Words"],"metadata":{"id":"6kr9xEpBaj5h"}},{"cell_type":"code","source":["documents = [\n","    \"Text processing is important for NLP.\",\n","    \"Bag of Words is a simple text representation method.\",\n","    \"Feature engineering is essential in machine learning.\"\n","]"],"metadata":{"id":"9f1GWctCan4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Sample text corpus\n","documents = [\n","    \"Text processing is important for NLP.\",\n","    \"Bag of Words is a simple text representation method.\",\n","    \"Feature engineering is essential in machine learning.\"\n","]\n","\n","# Initialize the CountVectorizer\n","vectorizer = CountVectorizer()\n","\n","# Transform the text data\n","X = vectorizer.fit_transform(documents)\n","\n","# Convert the result to an array\n","bow_array = X.toarray()\n","\n","# Get the feature names (vocabulary)\n","vocab = vectorizer.get_feature_names_out()\n","\n","print(\"Vocabulary:\")\n","print(vocab)\n","\n","print(\"\\nBag of Words Array:\")\n","print(bow_array)"],"metadata":{"id":"TQCAPPdVa6So"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"lyfw4x2ibuCu"}},{"cell_type":"markdown","source":["Exercise 2: TF-IDF"],"metadata":{"id":"JKkhULhpa9dT"}},{"cell_type":"code","source":["documents = [\n","    \"Natural language processing is fun.\",\n","    \"Language models are important in NLP.\",\n","    \"Machine learning and NLP are closely related.\"\n","]"],"metadata":{"id":"LJFk0O-qa_Jx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Sample text corpus\n","documents = [\n","    \"Natural language processing is fun.\",\n","    \"Language models are important in NLP.\",\n","    \"Machine learning and NLP are closely related.\"\n","]\n","\n","# Initialize the TfidfVectorizer\n","vectorizer = TfidfVectorizer()\n","\n","# Transform the text data\n","X = vectorizer.fit_transform(documents)\n","\n","# Convert the result to an array\n","tfidf_array = X.toarray()\n","\n","# Get the feature names (vocabulary)\n","vocab = vectorizer.get_feature_names_out()\n","\n","print(\"Vocabulary:\")\n","print(vocab)\n","\n","print(\"\\nTF-IDF Array:\")\n","print(tfidf_array)"],"metadata":{"id":"LNEw-dwMbCdK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"pstovR0obvTq"}},{"cell_type":"markdown","source":["Exercise 3: Word2Vec"],"metadata":{"id":"lY84-FgebKR7"}},{"cell_type":"code","source":["text = \"Natural language processing is fun and exciting. Language models are important in NLP. Machine learning and NLP are closely related.\""],"metadata":{"id":"VATJhHEKbMJX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","# Sample text corpus\n","text = \"Natural language processing is fun and exciting. Language models are important in NLP. Machine learning and NLP are closely related.\"\n","\n","# Tokenize the text into sentences\n","sentences = sent_tokenize(text)\n","\n","# Tokenize each sentence into words\n","tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n","\n","# Train a Word2Vec model using the Skip-Gram method\n","model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, sg=1, min_count=1)\n","\n","# Get the vector representation of the word \"NLP\"\n","vector = model.wv['NLP']\n","print(\"Vector representation of 'NLP':\")\n","print(vector)"],"metadata":{"id":"kQ4wQ1wjbNoW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"ZfaNdo89bwc6"}},{"cell_type":"markdown","source":["Exercise 4: GloVe"],"metadata":{"id":"RGHngQqlbPVi"}},{"cell_type":"code","source":["import gensim.downloader as api\n","\n","# Load pre-trained GloVe embeddings\n","glove_model = api.load(\"glove-wiki-gigaword-100\")\n","\n","# Get the vector representation of the word \"machine\"\n","vector = glove_model['machine']\n","print(\"Vector representation of 'machine':\")\n","print(vector)\n","\n","# Find the most similar words to \"machine\"\n","similar_words = glove_model.most_similar('machine')\n","print(\"\\nMost similar words to 'machine':\")\n","print(similar_words)"],"metadata":{"id":"Au42cQ9bbP_o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"RzwQbvTTbxaK"}},{"cell_type":"markdown","source":["Exercise 5: BERT Embeddings"],"metadata":{"id":"hoM5dMMobSkv"}},{"cell_type":"code","source":["text = \"Transformers are powerful models for NLP tasks.\""],"metadata":{"id":"nYjRWhzVbTGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel\n","import torch\n","\n","# Load pre-trained BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Sample text\n","text = \"Transformers are powerful models for NLP tasks.\"\n","\n","# Tokenize the text\n","inputs = tokenizer(text, return_tensors='pt')\n","\n","# Generate BERT embeddings\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Get the embeddings for the [CLS] token (representing the entire input text)\n","cls_embeddings = outputs.last_hidden_state[:, 0, :]\n","\n","print(\"BERT Embeddings for the text:\")\n","print(cls_embeddings)"],"metadata":{"id":"mxGRMXeHbVm_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"4Po0hLnYbyxS"}}]}