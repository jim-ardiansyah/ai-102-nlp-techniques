{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPYO10OFyfKgVV83kDubtg1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chapter-6 Assignments"],"metadata":{"id":"4pM0S3O8ialT"}},{"cell_type":"markdown","source":["**Installed the required Python prerequisite packages and libraries.**"],"metadata":{"id":"BlNtZNskBst8"}},{"cell_type":"code","source":["!pip install textblob\n","!pip install afinn\n","!pip install transformers\n","!pip install tensorflow"],"metadata":{"id":"dt4tLrxqBuVc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Exercise 1: Rule-Based Sentiment Analysis with TextBlob"],"metadata":{"id":"6k0KADm1ieWN"}},{"cell_type":"code","source":["from textblob import TextBlob\n","\n","# Sample texts\n","texts = [\n","    \"The weather is terrible today.\",\n","    \"I am so excited about the new movie release.\"\n","]\n","\n","# Perform sentiment analysis\n","for text in texts:\n","    blob = TextBlob(text)\n","    sentiment = blob.sentiment\n","    print(f\"Text: {text}\")\n","    print(f\"Polarity: {sentiment.polarity}, Subjectivity: {sentiment.subjectivity}\")\n","    print()"],"metadata":{"id":"sOdH15QWifyl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"Lnmt5l_6i0Zy"}},{"cell_type":"markdown","source":["Exercise 2: Custom Rule-Based Sentiment Analysis with Afinn"],"metadata":{"id":"IA3dLo1kihVb"}},{"cell_type":"code","source":["from afinn import Afinn\n","\n","# Initialize the Afinn sentiment analyzer\n","afinn = Afinn()\n","\n","# Sample texts\n","texts = [\n","    \"I hate waiting in long lines.\",\n","    \"The food at the restaurant was fantastic.\"\n","]\n","\n","# Perform sentiment analysis\n","for text in texts:\n","    sentiment_score = afinn.score(text)\n","    sentiment = \"Positive\" if sentiment_score > 0 else \"Negative\" if sentiment_score < 0 else \"Neutral\"\n","    print(f\"Text: {text}\")\n","    print(f\"Sentiment Score: {sentiment_score}\")\n","    print(f\"Sentiment: {sentiment}\")\n","    print()"],"metadata":{"id":"yo88M7xKiixm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"1RuubZ_ui1KP"}},{"cell_type":"markdown","source":["Exercise 3: Sentiment Analysis with Logistic Regression"],"metadata":{"id":"uayoS-DwimRD"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Sample text corpus and labels\n","corpus = [\n","    \"I love this product!\",\n","    \"This is the worst service.\",\n","    \"I am happy with my purchase.\",\n","    \"The quality is terrible.\"\n","]\n","labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n","\n","# Transform the text data into TF-IDF features\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n","\n","# Initialize and train the Logistic Regression model\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Predict the sentiment of the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(\"Classification Report:\")\n","print(report)"],"metadata":{"id":"LS3LVOMmim2-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"AULtgIDDi2Be"}},{"cell_type":"markdown","source":["Exercise 4: Sentiment Analysis with LSTMs"],"metadata":{"id":"PDc5Y7Knio7j"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","# Sample text corpus and labels\n","corpus = [\n","    \"I love this product!\",\n","    \"This is the worst service.\",\n","    \"I am happy with my purchase.\",\n","    \"The quality is terrible.\"\n","]\n","labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n","\n","# Tokenize and pad the text data\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(corpus)\n","X = tokenizer.texts_to_sequences(corpus)\n","X = pad_sequences(X, maxlen=10)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n","\n","# Convert data to TensorFlow Tensors\n","X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.int32)\n","X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.int32)\n","y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.int32)\n","y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.int32)\n","\n","\n","# Define the LSTM model\n","model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=50, input_length=10))\n","model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train_tensor, y_train_tensor, epochs=5, verbose=1, validation_data=(X_test_tensor, y_test_tensor))\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test_tensor, y_test_tensor)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Predict the sentiment of new text\n","new_text = [\"The product is excellent and I love it.\"]\n","new_text_seq = tokenizer.texts_to_sequences(new_text)\n","new_text_padded = pad_sequences(new_text_seq, maxlen=10)\n","new_text_tensor = tf.convert_to_tensor(new_text_padded, dtype=tf.int32)\n","prediction = model.predict(new_text_tensor)\n","print(\"Prediction:\", \"Positive\" if prediction[0][0] > 0.5 else \"Negative\")"],"metadata":{"id":"Lki6fCq9isWk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"p5xEH6Sqi3Jy"}},{"cell_type":"markdown","source":["Exercise 5: Sentiment Analysis with BERT"],"metadata":{"id":"wEtk2n8yit6y"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from sklearn.model_selection import train_test_split\n","\n","# Sample text corpus and labels\n","corpus = [\n","    \"I love this product!\",\n","    \"This is the worst service.\",\n","    \"I am happy with my purchase.\",\n","    \"The quality is terrible.\"\n","]\n","labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n","\n","# Initialize the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize and encode the text data\n","X = tokenizer(corpus, padding=True, truncation=True, max_length=10, return_tensors='tf')\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X['input_ids'].numpy(), labels, test_size=0.25, random_state=42)\n","\n","# Initialize the BERT model for sequence classification\n","model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, from_pt=True, use_safetensors=False)\n","# model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n"," metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, np.array(y_train), epochs=3, batch_size=8, validation_data=(X_test, np.array(y_test)))\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, np.array(y_test))\n","display(f\"Accuracy: {accuracy}\")\n","\n","# Predict the sentiment of new text\n","new_text = [\"The product is excellent and I love it.\"]\n","new_text_enc = tokenizer(new_text, padding=True, truncation=True, max_length=10, return_tensors='tf')\n","prediction = model.predict(new_text_enc['input_ids'])\n","display(\"Prediction:\", \"Positive\" if np.argmax(prediction.logits) == 1 else \"Negative\")"],"metadata":{"id":"L910HTppiv3c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  "],"metadata":{"id":"-5_WMIxui3-5"}}]}