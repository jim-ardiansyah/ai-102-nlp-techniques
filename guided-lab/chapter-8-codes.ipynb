{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 8.1 Extractive Summarization"],"metadata":{"id":"kxunHxq4qVPD"}},{"cell_type":"markdown","source":["**Installed the required Python prerequisite packages and libraries.**"],"metadata":{"id":"-JDGYKAY9lqK"}},{"cell_type":"code","source":["!pip install nltk\n","!pip install sumy\n","!pip install gensim\n","!pip install transformers"],"metadata":{"id":"wEx78a0Cqb2P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8.1.2 Implementing Extractive Summarization"],"metadata":{"id":"KWtbXAgMqaPL"}},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.probability import FreqDist\n","from nltk.cluster.util import cosine_distance\n","import numpy as np\n","import networkx as nx\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","\n","# Sample text\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# Preprocess the text\n","sentences = sent_tokenize(text)\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess_sentence(sentence):\n","    words = word_tokenize(sentence.lower())\n","    words = [word for word in words if word.isalnum() and word not in stop_words]\n","    return words\n","\n","# Sentence scoring based on term frequency\n","def score_sentences(sentences):\n","    sentence_scores = []\n","    word_frequencies = FreqDist([word for sentence in sentences for word in preprocess_sentence(sentence)])\n","\n","    for sentence in sentences:\n","        words = preprocess_sentence(sentence)\n","        sentence_score = sum(word_frequencies[word] for word in words)\n","        sentence_scores.append((sentence, sentence_score))\n","\n","    return sentence_scores\n","\n","# Select top-ranked sentences\n","def select_sentences(sentence_scores, num_sentences=2):\n","    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n","    selected_sentences = [sentence[0] for sentence in sentence_scores[:num_sentences]]\n","    return selected_sentences\n","\n","# Generate summary\n","sentence_scores = score_sentences(sentences)\n","summary_sentences = select_sentences(sentence_scores)\n","summary = ' '.join(summary_sentences)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"y1k2dQvFqh-x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8.1.3 Advanced Extractive Summarization Techniques"],"metadata":{"id":"AjR8YWnVrW0k"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","import numpy as np\n","import networkx as nx\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# NLTK downloads (depending on the environment, 'punkt_tab' may also be required)\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Sample text (replace with the reader's input)\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# 1) Sentences and light normalization\n","sentences = [s for s in sent_tokenize(text) if s.strip()]\n","stop_words = set(stopwords.words('english'))\n","\n","def normalize(s):\n","    tokens = [w for w in word_tokenize(s.lower()) if w.isalnum() and w not in stop_words]\n","    return \" \".join(tokens)\n","\n","normalized = [normalize(s) for s in sentences]\n","\n","# 2) TF-IDF vectorization per sentence\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(normalized)   # shape: (n_sentences, vocab_size)\n","\n","# 3) Cosine similarity matrix\n","sim_matrix = cosine_similarity(X, X)\n","np.fill_diagonal(sim_matrix, 0.0)          # avoid dominant self-loops\n","\n","# 4) TextRank with NetworkX (PageRank over the similarity graph)\n","graph = nx.from_numpy_array(sim_matrix)\n","scores = nx.pagerank(graph)\n","\n","# 5) Selection of top-ranked sentences\n","num_sentences = 2\n","ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n","summary_sentences = [s for _, s in ranked[:num_sentences]]\n","summary = \" \".join(summary_sentences)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"qd3vVh3PrhX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample documents\n","documents = [\n","    \"The cat sat on the mat\",\n","    \"The dog chased the ball\",\n","    \"The bird flew in the sky\"\n","]\n","\n","# Create a term-document matrix (one-hot encoded)\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer = CountVectorizer()\n","term_document_matrix = vectorizer.fit_transform(documents)\n","\n","# Perform Singular Value Decomposition (SVD)\n","from sklearn.decomposition import TruncatedSVD\n","svd = TruncatedSVD(n_components=2)  # Reduce dimensionality to 2 for visualization\n","lsa_matrix = svd.fit_transform(term_document_matrix)\n","\n","# Reduced term and document representations (topics)\n","terms = vectorizer.get_feature_names_out()\n","lsa_topics = svd.components_\n","\n","# Print the results (example)\n","print(\"Terms:\", terms)\n","print(\"Reduced Document Representations (Topics):\")\n","print(lsa_matrix)\n","print(\"Reduced Term Representations (Topics):\")\n","print(lsa_topics)"],"metadata":{"id":"TPB3mR_Ur2hZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8.2 Abstractive Summarization"],"metadata":{"id":"OyZmvslotL-f"}},{"cell_type":"markdown","source":["8.2.2 Implementing Abstractive Summarization"],"metadata":{"id":"b0oT45dOtOQO"}},{"cell_type":"code","source":["from transformers import BartForConditionalGeneration, BartTokenizer\n","\n","# Load the pre-trained BART model and tokenizer\n","model_name = \"facebook/bart-large-cnn\"\n","model = BartForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = BartTokenizer.from_pretrained(model_name)\n","\n","# Sample text\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# Tokenize and encode the text\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"NHs_YDzItRpu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8.2.3 Advanced Abstractive Summarization Techniques"],"metadata":{"id":"-xoMt50GtVB8"}},{"cell_type":"code","source":["from transformers import T5ForConditionalGeneration, T5Tokenizer\n","\n","# Load the pre-trained T5 model and tokenizer\n","model_name = \"t5-small\"\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","\n","# Sample text\n","text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language, in particular how to program computers to process\n","and analyze large amounts of natural language data. Challenges in natural language processing frequently involve speech\n","recognition, natural language understanding, and natural language generation.\"\"\"\n","\n","# Tokenize and encode the text\n","inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Generate the summary\n","summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Summary:\")\n","print(summary)"],"metadata":{"id":"Fm1uefattVvm"},"execution_count":null,"outputs":[]}]}