{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 7.1 Latent Semantic Analysis (LSA)"],"metadata":{"id":"WI1mxRQ0oLgR"}},{"cell_type":"markdown","source":["**Installed the required Python prerequisite packages and libraries.**"],"metadata":{"id":"tVlelQve7qCV"}},{"cell_type":"code","source":["!pip install scikit-learn\n","!pip install gensim"],"metadata":{"id":"VHkI4iJtoQER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7.1.3 Implementing LSA in Python."],"metadata":{"id":"-7PxuMmuoOJE"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","\n","# Sample text corpus\n","corpus = [\n","    \"The cat sat on the mat.\",\n","    \"The dog sat on the log.\",\n","    \"The cat chased the dog.\",\n","    \"The dog chased the cat.\"\n","]\n","\n","# Create a TF-IDF Vectorizer\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","\n","# Apply LSA using TruncatedSVD\n","lsa = TruncatedSVD(n_components=2, random_state=42)\n","X_reduced = lsa.fit_transform(X)\n","\n","# Print the terms and their corresponding components\n","terms = vectorizer.get_feature_names_out()\n","for i, comp in enumerate(lsa.components_):\n","    terms_comp = zip(terms, comp)\n","    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:5]\n","    print(f\"Topic {i}:\")\n","    for term, weight in sorted_terms:\n","        print(f\" - {term}: {weight:.4f}\")"],"metadata":{"id":"WqKyv6WdoUw2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7.2 Latent Dirichlet Allocation (LDA)"],"metadata":{"id":"n3RjzdA6oafs"}},{"cell_type":"markdown","source":["7.2.3 Implementing LDA in Python"],"metadata":{"id":"eWIg34p8ocKh"}},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import LdaModel\n","from pprint import pprint\n","\n","# Sample text corpus\n","corpus = [\n","    \"The cat sat on the mat.\",\n","    \"The dog sat on the log.\",\n","    \"The cat chased the dog.\",\n","    \"The dog chased the cat.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents\n","dictionary = corpora.Dictionary(texts)\n","\n","# Convert the dictionary to a bag-of-words representation of the corpus\n","corpus_bow = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train the LDA model\n","lda_model = LdaModel(corpus=corpus_bow, id2word=dictionary, num_topics=2, random_state=42, passes=10)\n","\n","# Print the topics\n","print(\"Topics:\")\n","pprint(lda_model.print_topics(num_words=5))\n","\n","# Assign topics to a new document\n","new_doc = \"The cat chased the dog.\"\n","new_doc_bow = dictionary.doc2bow(new_doc.lower().split())\n","print(\"\\\\nTopic Distribution for the new document:\")\n","pprint(lda_model.get_document_topics(new_doc_bow))"],"metadata":{"id":"0OLzN8eeod-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7.2.4 Interpreting LDA Results"],"metadata":{"id":"9ipoo0hzoh6P"}},{"cell_type":"code","source":["from gensim.models.coherencemodel import CoherenceModel\n","\n","# Compute Coherence Score\n","coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n","coherence_lda = coherence_model_lda.get_coherence()\n","print(f\"Coherence Score: {coherence_lda}\")"],"metadata":{"id":"CjvyJ6TBoiji"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7.3 Hierarchical Dirichlet Process (HDP)"],"metadata":{"id":"0fPfVG8kotpo"}},{"cell_type":"markdown","source":["7.3.3 Implementing HDP in Python"],"metadata":{"id":"bhscXPKhovlG"}},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import HdpModel\n","from pprint import pprint\n","\n","# Sample text corpus\n","corpus = [\n","    \"The cat sat on the mat.\",\n","    \"The dog sat on the log.\",\n","    \"The cat chased the dog.\",\n","    \"The dog chased the cat.\"\n","]\n","\n","# Tokenize the text and remove stop words\n","texts = [[word for word in document.lower().split()] for document in corpus]\n","\n","# Create a dictionary representation of the documents\n","dictionary = corpora.Dictionary(texts)\n","\n","# Convert the dictionary to a bag-of-words representation of the corpus\n","corpus_bow = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train the HDP model\n","hdp_model = HdpModel(corpus=corpus_bow, id2word=dictionary)\n","\n","# Print the topics\n","print(\"Topics:\")\n","pprint(hdp_model.print_topics(num_topics=2, num_words=5))\n","\n","# Assign topics to a new document\n","new_doc = \"The cat chased the dog.\"\n","new_doc_bow = dictionary.doc2bow(new_doc.lower().split())\n","print(\"\\\\nTopic Distribution for the new document:\")\n","pprint(hdp_model[new_doc_bow])"],"metadata":{"id":"0KR3jr0pozKJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7.3.4 Interpreting HDP Results"],"metadata":{"id":"MdxAglP2o2AE"}},{"cell_type":"code","source":["from gensim.models.coherencemodel import CoherenceModel\n","\n","# Compute Coherence Score\n","coherence_model_hdp = CoherenceModel(model=hdp_model, texts=texts, dictionary=dictionary, coherence='c_v')\n","coherence_hdp = coherence_model_hdp.get_coherence()\n","print(f\"Coherence Score: {coherence_hdp}\")"],"metadata":{"id":"NhyvYkHPo3_V"},"execution_count":null,"outputs":[]}]}