{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Tm09GiC_QnNzlCUIkJSRPdLxOz3qJfqC","timestamp":1757379034656}],"toc_visible":true,"authorship_tag":"ABX9TyOoWKKhhUiz6u+h7FMUvML3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zF6dXAoF8oC1"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# What's NLP?"],"metadata":{"id":"8JQ-mEfW9QK8"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')  # Download the necessary resources\n","\n","from nltk.tokenize import word_tokenize\n","\n","# Sample text\n","text = \"Natural Language Processing (NLP) enables machines to understand human language.\"\n","\n","# Tokenizing the text\n","tokens = word_tokenize(text)\n","\n","# Display the tokens\n","print(tokens)"],"metadata":{"id":"p-4fafsg9V_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk"],"metadata":{"id":"vKpypvP29aMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"id":"aM75TBfN9bs_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize"],"metadata":{"id":"l71ynob_9fED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"Natural Language Processing (NLP) enables machines to understand human language.\""],"metadata":{"id":"zgugl9Fh9gc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = word_tokenize(text)"],"metadata":{"id":"FSFiDf0y9h0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokens)"],"metadata":{"id":"rZrCIpXk9jMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'enables', 'machines', 'to', 'understand', 'human', 'language', '.']"],"metadata":{"id":"AVSFqmSd9kkx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Significance and Application of NLP"],"metadata":{"id":"N4i0JE4m9mOB"}},{"cell_type":"code","source":["from translate import Translator\n","\n","# Create a translator object\n","translator = Translator(to_lang=\"es\")\n","\n","# Translate a phrase\n","translation = translator.translate(\"How are you?\")\n","print(translation)  # Output: ¿Cómo estás?"],"metadata":{"id":"KIe5n8B09thr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from translate import Translator"],"metadata":{"id":"9Ps4kfXf9wA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator = Translator(to_lang=\"es\")"],"metadata":{"id":"UpqlzG2j9znE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translation = translator.translate(\"How are you?\")"],"metadata":{"id":"xeHnXINk908a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(translation)  # Output: ¿Cómo estás?"],"metadata":{"id":"IIAs4jyy92Ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from textblob import TextBlob\n","\n","# Sample text\n","text = \"I love this product! It's amazing.\"\n","\n","# Create a TextBlob object\n","blob = TextBlob(text)\n","\n","# Perform sentiment analysis\n","sentiment = blob.sentiment\n","print(sentiment)  # Output: Sentiment(polarity=0.65, subjectivity=0.6)"],"metadata":{"id":"RPkCCXTi942u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","\n","# Sample text\n","text = \"\"\"\n","Natural Language Processing (NLP) is a fascinating field at the intersection of computer science, artificial intelligence, and linguistics. It enables machines to understand, interpret, and generate human language, opening up a world of possibilities for applications ranging from chatbots and translation services to sentiment analysis and beyond.\n","\"\"\"\n","\n","# Create a parser\n","parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","\n","# Create a summarizer\n","summarizer = LsaSummarizer()\n","\n","# Generate the summary\n","summary = summarizer(parser.document, 2)  # Summarize to 2 sentences\n","for sentence in summary:\n","    print(sentence)"],"metadata":{"id":"gdQ5eTIh95hf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Real-World Example: E-commerce Review Analysis"],"metadata":{"id":"zl2ehIqF9-4W"}},{"cell_type":"code","source":["import nltk\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","# Sample reviews\n","reviews = [\n","    \"This product is fantastic! It exceeded my expectations.\",\n","    \"Not worth the price. I'm disappointed with the quality.\",\n","    \"Good value for money. Will buy again.\",\n","]\n","\n","# Initialize the sentiment analyzer\n","nltk.download('vader_lexicon')\n","sia = SentimentIntensityAnalyzer()\n","\n","# Analyze each review\n","for review in reviews:\n","    sentiment = sia.polarity_scores(review)\n","    print(f\"Review: {review}\\\\nSentiment: {sentiment}\\\\n\")"],"metadata":{"id":"e8LyDOuJ-Aq_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Overview of Python for NLP"],"metadata":{"id":"hoJKWNOQ-Rli"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","text = \"Natural Language Processing with Python is fun!\"\n","tokens = word_tokenize(text)\n","print(tokens)"],"metadata":{"id":"nqqCa66P-US3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import spacy\n","\n","# Load SpaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n","doc = nlp(text)\n","\n","# Extract named entities\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"id":"xfePL9rf-XfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","# Sample sentences\n","sentences = [\n","    [\"natural\", \"language\", \"processing\"],\n","    [\"python\", \"is\", \"a\", \"powerful\", \"language\"],\n","    [\"text\", \"processing\", \"with\", \"gensim\"],\n","]\n","\n","# Train Word2Vec model\n","model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n","\n","# Get vector for a word\n","vector = model.wv['language']\n","print(vector)"],"metadata":{"id":"yjFHOd2l-ZaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec"],"metadata":{"id":"fQgZIv-4-gBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = [\n","    [\"natural\", \"language\", \"processing\"],\n","    [\"python\", \"is\", \"a\", \"powerful\", \"language\"],\n","    [\"text\", \"processing\", \"with\", \"gensim\"],\n","]"],"metadata":{"id":"vssAqEqc-ghu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"],"metadata":{"id":"_6KAL_dF-lVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector = model.wv['language']\n","print(vector)"],"metadata":{"id":"EvTy3M3W-mH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","# Sample data\n","texts = [\"I love this product\", \"This is the worst experience\", \"Absolutely fantastic!\", \"Not good at all\"]\n","labels = [1, 0, 1, 0]\n","\n","# Vectorize text data\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(texts)\n","\n","# Train a Naive Bayes classifier\n","classifier = MultinomialNB()\n","classifier.fit(X, labels)\n","\n","# Predict sentiment for a new text\n","new_text = [\"I hate this\"]\n","X_new = vectorizer.transform(new_text)\n","prediction = classifier.predict(X_new)\n","print(prediction)"],"metadata":{"id":"JoeskTBx-omd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Setting Up Your Python Environment for NLP"],"metadata":{"id":"jSlhfdpI-tPK"}},{"cell_type":"code","source":["python --version"],"metadata":{"id":"xIe2npGe-va7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["python -m venv nlp_env"],"metadata":{"id":"l-2jwyyq-xuk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp_env\\\\Scripts\\\\activate"],"metadata":{"id":"6hMtX7vn-zSQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["source nlp_env/bin/activate"],"metadata":{"id":"hnfO-T0E-1w1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install nltk spacy gensim scikit-learn"],"metadata":{"id":"FbgEHDGM-4vE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","import spacy\n","from gensim.models import Word2Vec\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Verify NLTK\n","nltk.download('punkt')\n","text = \"Natural Language Processing with Python is fun!\"\n","tokens = word_tokenize(text)\n","print(\"NLTK Tokens:\", tokens)\n","\n","# Verify SpaCy\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(text)\n","print(\"SpaCy Tokens:\", [token.text for token in doc])\n","\n","# Verify gensim\n","sentences = [[\"natural\", \"language\", \"processing\"], [\"python\", \"is\", \"fun\"]]\n","model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n","print(\"Word2Vec Vocabulary:\", list(model.wv.index_to_key))\n","\n","# Verify scikit-learn\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform([text])\n","print(\"CountVectorizer Feature Names:\", vectorizer.get_feature_names_out())"],"metadata":{"id":"vsn6hr8Q-7CV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["python test_nlp.py"],"metadata":{"id":"PrTtji_Z-9FE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NLTK Tokens: ['Natural', 'Language', 'Processing', 'with', 'Python', 'is', 'fun', '!']\n","SpaCy Tokens: ['Natural', 'Language', 'Processing', 'with', 'Python', 'is', 'fun', '!']\n","Word2Vec Vocabulary: ['natural', 'language', 'processing', 'python', 'is', 'fun']\n","CountVectorizer Feature Names: ['fun', 'is', 'language', 'natural', 'processing', 'python', 'with']"],"metadata":{"id":"i2GO3lOn-9ut"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example: End-to-End NLP Pipeline"],"metadata":{"id":"kzWvIJH1_CGG"}},{"cell_type":"code","source":["import nltk\n","import spacy\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","# Sample data\n","texts = [\n","    \"I love this product! It's amazing.\",\n","    \"This is the worst experience I've ever had.\",\n","    \"Absolutely fantastic! Highly recommend.\",\n","    \"Not good at all. Very disappointing.\"\n","]\n","labels = [1, 0, 1, 0]\n","\n","# Load SpaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Custom tokenizer using SpaCy\n","def spacy_tokenizer(sentence):\n","    doc = nlp(sentence)\n","    return [token.text for token in doc]\n","\n","# Stop words\n","stop_words = set(stopwords.words('english'))\n","\n","# Define the pipeline\n","pipeline = Pipeline([\n","    ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, stop_words=list(stop_words))),\n","    ('classifier', MultinomialNB())\n","])\n","\n","# Train the model\n","pipeline.fit(texts, labels)\n","\n","# Predict sentiment for a new text\n","new_text = [\"I hate this product\"]\n","prediction = pipeline.predict(new_text)\n","print(prediction)"],"metadata":{"id":"iQXbJOyx_EMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","import spacy\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')"],"metadata":{"id":"QXuqnrW9_IC1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = [\n","    \"I love this product! It's amazing.\",\n","    \"This is the worst experience I've ever had.\",\n","    \"Absolutely fantastic! Highly recommend.\",\n","    \"Not good at all. Very disappointing.\"\n","]\n","labels = [1, 0, 1, 0]"],"metadata":{"id":"JLJYTCLM_Jqp","executionInfo":{"status":"ok","timestamp":1757379882894,"user_tz":300,"elapsed":11,"user":{"displayName":"Jimmy Ardiansyah","userId":"06913112371375508078"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"JWXcOzTo_LZ7","executionInfo":{"status":"ok","timestamp":1757379886299,"user_tz":300,"elapsed":661,"user":{"displayName":"Jimmy Ardiansyah","userId":"06913112371375508078"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def spacy_tokenizer(sentence):\n","    doc = nlp(sentence)\n","    return [token.text for token in doc]"],"metadata":{"id":"yXTk-cAh_M1B","executionInfo":{"status":"ok","timestamp":1757379888527,"user_tz":300,"elapsed":4,"user":{"displayName":"Jimmy Ardiansyah","userId":"06913112371375508078"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["stop_words = set(stopwords.words('english'))"],"metadata":{"id":"qsp5HHQk_OZU","executionInfo":{"status":"ok","timestamp":1757379891192,"user_tz":300,"elapsed":5,"user":{"displayName":"Jimmy Ardiansyah","userId":"06913112371375508078"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["pipeline = Pipeline([\n","    ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, stop_words=list(stop_words))),\n","    ('classifier', MultinomialNB())\n","])"],"metadata":{"id":"y7PpYgXh_P2e","executionInfo":{"status":"ok","timestamp":1757379947877,"user_tz":300,"elapsed":9,"user":{"displayName":"Jimmy Ardiansyah","userId":"06913112371375508078"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["pipeline.fit(texts, labels)"],"metadata":{"id":"DqR6mVYa_Q_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_text = [\"I hate this product\"]\n","prediction = pipeline.predict(new_text)\n","print(prediction)"],"metadata":{"id":"rMMvnvts_SHN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chapter-1 Assignment"],"metadata":{"id":"jkuoN7uaBAZE"}},{"cell_type":"markdown","source":["Exercise 1: Tokenization with NLTK"],"metadata":{"id":"JN4Eg-03BFkb"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","text = \"Natural Language Processing enables computers to understand human language.\"\n","tokens = word_tokenize(text)\n","print(tokens)"],"metadata":{"id":"5soL5XG4BHbR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"IMl5jDAKC0xp"}},{"cell_type":"markdown","source":["Exercise 2: Named Entity Recognition with SpaCy"],"metadata":{"id":"eVpJE0_KBMoM"}},{"cell_type":"code","source":["import spacy\n","\n","# Load SpaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","text = \"Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\"\n","doc = nlp(text)\n","\n","# Extract named entities\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"id":"0wvw7PviBOgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XX7e1xfEErKa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"lgpl9ncKD565"}},{"cell_type":"markdown","source":["Exercise 3: Sentiment Analysis with TextBlob"],"metadata":{"id":"km7HYbODBQhv"}},{"cell_type":"code","source":["from textblob import TextBlob\n","\n","text = \"I am extremely happy with the service provided.\"\n","blob = TextBlob(text)\n","sentiment = blob.sentiment\n","print(sentiment)"],"metadata":{"id":"NDsO3jy1BSSl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"N-cR5k_zD9ZT"}},{"cell_type":"markdown","source":["Exercise 4: Text Summarization with sumy"],"metadata":{"id":"EqNsrUKFBVmA"}},{"cell_type":"code","source":["!pip install sumy"],"metadata":{"id":"b7XCf3H5Bh68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\\\n","\n","text = \"\"\"\n","Natural Language Processing (NLP) is a fascinating field at the intersection of computer science, artificial intelligence, and linguistics. It enables machines to understand, interpret, and generate human language, opening up a world of possibilities for applications ranging from chatbots and translation services to sentiment analysis and beyond. The evolution of NLP has been driven by significant advances in machine learning and deep learning, which have enabled more sophisticated and accurate models for language understanding. This book aims to bring these cutting-edge techniques to you in an accessible and practical way, regardless of your current level of expertise.\n","\"\"\"\n","\n","\n","parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","summarizer = LsaSummarizer()\n","summary = summarizer(parser.document, 2)\n","for sentence in summary:\n","    print(sentence)"],"metadata":{"id":"neYVoP5uBY6L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"b2P_3gDLD_oQ"}},{"cell_type":"markdown","source":["Exercise 5: Text Classification with scikit-learn"],"metadata":{"id":"OwaPv-KLCfp4"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","texts = [\"I love this product\", \"This is the worst experience\", \"Absolutely fantastic!\", \"Not good at all\"]\n","labels = [1, 0, 1, 0]\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(texts)\n","\n","classifier = MultinomialNB()\n","classifier.fit(X, labels)\n","\n","new_text = [\"This experience was fantastic\"]\n","X_new = vectorizer.transform(new_text)\n","prediction = classifier.predict(X_new)\n","print(prediction)"],"metadata":{"id":"lUsOpNdLChfw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Explain the code snippet above in detail. **\n","\n","___\n","\n","**Type Your ResponseBelow:**  \n"],"metadata":{"id":"luZnfuGPEBNP"}}]}