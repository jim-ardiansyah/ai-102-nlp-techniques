{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Tm09GiC_QnNzlCUIkJSRPdLxOz3qJfqC","timestamp":1757379034656}],"toc_visible":true,"authorship_tag":"ABX9TyPHECO9EH1MP1unH2CYdCkU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1.1 What is Natural Language Processing (NLP)?"],"metadata":{"id":"8JQ-mEfW9QK8"}},{"cell_type":"markdown","source":["**Installed the required Python prerequisite packages and libraries.**"],"metadata":{"id":"p8H44DoRXCuL"}},{"cell_type":"code","source":["!pip install translate\n","!pip install sumy\n","!pip install gensim"],"metadata":{"id":"J0kZmUb9XPK1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.1.4 Example: Tokenization in NLP\n","Here's a concise breakdown of what each part of the code does:\n","\n","1. **Importing NLTK:**  \n","   `import nltk` brings in the Natural Language Toolkit (NLTK), a widely used Python library for processing and analyzing human language data.\n","\n","2. **Downloading Tokenizer Models:**  \n","   `nltk.download('punkt')` and `nltk.download('punkt_tab')` download the necessary data for tokenization. The 'punkt' model is essential for splitting text into words and punctuation marks. While 'punkt' is the main requirement for basic tokenization, 'punkt_tab' is also included here, though it's not typically needed for standard use.\n","\n","3. **Importing the Tokenizer Function:**  \n","   `from nltk.tokenize import word_tokenize` imports the `word_tokenize` function, which is specifically designed to break text into individual tokens (words and punctuation).\n","\n","4. **Defining the Text:**  \n","   `text = \"Natural Language Processing (NLP) enables machines to understand human language.\"` sets up a sample string to demonstrate tokenization.\n","\n","5. **Tokenizing the Text:**  \n","   `tokens = word_tokenize(text)` applies the tokenizer to the sample text, resulting in a list of tokens (words and punctuation marks).\n","\n","6. **Displaying the Tokens:**  \n","   `print(tokens)` outputs the list of tokens to the console, allowing you to see the result of the tokenization process.\n","\n","**Note:** Downloading the 'punkt' data is only necessary the first time you use it on your system."],"metadata":{"id":"GWSzM374jQ2d"}},{"cell_type":"code","source":["\n","# Download the necessary library and resources\n","import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","from nltk.tokenize import word_tokenize\n","\n","# Sample text\n","text = \"Natural Language Processing (NLP) enables machines to understand human language.\"\n","\n","# Tokenizing the text\n","tokens = word_tokenize(text)\n","\n","# Display the tokens\n","print(tokens)"],"metadata":{"id":"p-4fafsg9V_U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.2 Significance and Applications of NLP\n","\n"],"metadata":{"id":"N4i0JE4m9mOB"}},{"cell_type":"markdown","source":["1.2.2 Uses of NLP with Examples"],"metadata":{"id":"qcS9VAFhS7fT"}},{"cell_type":"code","source":["\n","from translate import Translator\n","\n","# Create a translator object\n","translator = Translator(to_lang=\"es\")\n","\n","# Translate a phrase\n","translation = translator.translate(\"How are you?\")\n","print(translation)  # Output: ¿Cómo estás?\n"],"metadata":{"id":"KIe5n8B09thr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from textblob import TextBlob\n","\n","# Sample text\n","text = \"I love this product! It's amazing.\"\n","\n","# Create a TextBlob object\n","blob = TextBlob(text)\n","\n","# Perform sentiment analysis\n","sentiment = blob.sentiment\n","print(sentiment)  # Output: Sentiment(polarity=0.65, subjectivity=0.6)"],"metadata":{"id":"RPkCCXTi942u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","\n","# Sample text\n","text = \"\"\"\n","Natural Language Processing (NLP) is a fascinating field at the intersection of computer science, artificial intelligence, and linguistics. It enables machines to understand, interpret, and generate human language, opening up a world of possibilities for applications ranging from chatbots and translation services to sentiment analysis and beyond.\n","\"\"\"\n","\n","# Create a parser\n","parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n","\n","# Create a summarizer\n","summarizer = LsaSummarizer()\n","\n","# Generate the summary\n","summary = summarizer(parser.document, 2)  # Summarize to 2 sentences\n","for sentence in summary:\n","    print(sentence)"],"metadata":{"id":"gdQ5eTIh95hf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.2.3 Real-World Example: E-commerce Review Analysis"],"metadata":{"id":"zl2ehIqF9-4W"}},{"cell_type":"code","source":["import nltk\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","# Sample reviews\n","reviews = [\n","    \"This product is fantastic! It exceeded my expectations.\",\n","    \"Not worth the price. I'm disappointed with the quality.\",\n","    \"Good value for money. Will buy again.\",\n","]\n","\n","# Initialize the sentiment analyzer\n","nltk.download('vader_lexicon')\n","sia = SentimentIntensityAnalyzer()\n","\n","# Analyze each review\n","for review in reviews:\n","    sentiment = sia.polarity_scores(review)\n","    print(f\"Review: {review}\\\\nSentiment: {sentiment}\\\\n\")"],"metadata":{"id":"e8LyDOuJ-Aq_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# 1.3 Overview of Python for NLP"],"metadata":{"id":"hoJKWNOQ-Rli"}},{"cell_type":"markdown","source":["1.3.2 Key Python Libraries for NLP with Examples"],"metadata":{"id":"lDnzk8GhTag2"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","text = \"Natural Language Processing with Python is fun!\"\n","tokens = word_tokenize(text)\n","print(tokens)"],"metadata":{"id":"nqqCa66P-US3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import spacy\n","\n","# Load SpaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n","doc = nlp(text)\n","\n","# Extract named entities\n","for ent in doc.ents:\n","    print(ent.text, ent.label_)"],"metadata":{"id":"xfePL9rf-XfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","# Sample sentences\n","sentences = [\n","    [\"natural\", \"language\", \"processing\"],\n","    [\"python\", \"is\", \"a\", \"powerful\", \"language\"],\n","    [\"text\", \"processing\", \"with\", \"gensim\"],\n","]\n","\n","# Train Word2Vec model\n","model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n","\n","# Get vector for a word\n","vector = model.wv['language']\n","print(vector)"],"metadata":{"id":"yjFHOd2l-ZaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","# Sample data\n","texts = [\"I love this product\", \"This is the worst experience\", \"Absolutely fantastic!\", \"Not good at all\"]\n","labels = [1, 0, 1, 0]\n","\n","# Vectorize text data\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(texts)\n","\n","# Train a Naive Bayes classifier\n","classifier = MultinomialNB()\n","classifier.fit(X, labels)\n","\n","# Predict sentiment for a new text\n","new_text = [\"I hate this\"]\n","X_new = vectorizer.transform(new_text)\n","prediction = classifier.predict(X_new)\n","print(prediction)"],"metadata":{"id":"JoeskTBx-omd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.3.3 Setting Up Your Python Environment for NLP\n"],"metadata":{"id":"jSlhfdpI-tPK"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","import spacy\n","from gensim.models import Word2Vec\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Verify NLTK\n","nltk.download('punkt')\n","text = \"Natural Language Processing with Python is fun!\"\n","tokens = word_tokenize(text)\n","print(\"NLTK Tokens:\", tokens)\n","\n","# Verify SpaCy\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(text)\n","print(\"SpaCy Tokens:\", [token.text for token in doc])\n","\n","# Verify gensim\n","sentences = [[\"natural\", \"language\", \"processing\"], [\"python\", \"is\", \"fun\"]]\n","model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n","print(\"Word2Vec Vocabulary:\", list(model.wv.index_to_key))\n","\n","# Verify scikit-learn\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform([text])\n","print(\"CountVectorizer Feature Names:\", vectorizer.get_feature_names_out())"],"metadata":{"id":"vsn6hr8Q-7CV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.3.4 Example: End-to-End NLP Pipeline"],"metadata":{"id":"kzWvIJH1_CGG"}},{"cell_type":"code","source":["import nltk\n","import spacy\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","# Sample data\n","texts = [\n","    \"I love this product! It's amazing.\",\n","    \"This is the worst experience I've ever had.\",\n","    \"Absolutely fantastic! Highly recommend.\",\n","    \"Not good at all. Very disappointing.\"\n","]\n","labels = [1, 0, 1, 0]\n","\n","# Load SpaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Custom tokenizer using SpaCy\n","def spacy_tokenizer(sentence):\n","    doc = nlp(sentence)\n","    return [token.text for token in doc]\n","\n","# Stop words\n","stop_words = set(stopwords.words('english'))\n","\n","# Define the pipeline\n","pipeline = Pipeline([\n","    ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, stop_words=list(stop_words))),\n","    ('classifier', MultinomialNB())\n","])\n","\n","# Train the model\n","pipeline.fit(texts, labels)\n","\n","# Predict sentiment for a new text\n","new_text = [\"I hate this product\"]\n","prediction = pipeline.predict(new_text)\n","print(prediction)"],"metadata":{"id":"iQXbJOyx_EMY"},"execution_count":null,"outputs":[]}]}